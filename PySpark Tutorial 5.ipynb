{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce2ced1c-7795-471f-bb9c-eb1280838da8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n  Using cached pyspark-3.5.1-py2.py3-none-any.whl\r\nCollecting py4j==0.10.9.7\r\n  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\r\nInstalling collected packages: py4j, pyspark\r\nSuccessfully installed py4j-0.10.9.7 pyspark-3.5.1\r\n\u001B[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\r\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-8f109e50-4a8d-4f4e-99dd-ac19a9f0c446/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"tutorials\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c78c07fc-e05c-4499-927c-baceb484c4bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------+\n|     Name|  Department|Salary|\n+---------+------------+------+\n|    Krish|Data Science| 10000|\n|    Krish|         IOT|  5000|\n|    Krish|    Big Data|  4000|\n|Sudhanshu|Data Science| 20000|\n|    Sunny|Data Science| 10000|\n|   Mahesh|    Big Data|  4000|\n|Sudhanshu|         IOT| 10000|\n|   Mahesh|Data Science|  3000|\n|Sudhanshu|    Big Data|  5000|\n+---------+------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.csv(\"/FileStore/tables/PySparkTutoria/sample5.csv\", inferSchema=True, header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cb281b9-041f-461a-8b06-28d422207df1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n|     Name|sum(Salary)|\n+---------+-----------+\n|Sudhanshu|      35000|\n|    Sunny|      10000|\n|    Krish|      19000|\n|   Mahesh|       7000|\n+---------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Finding Total Salary of the People\n",
    "df.groupBy('Name').sum('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "838354b4-4e17-4d5c-bbfa-74da0abfc4ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n|  Department|sum(Salary)|\n+------------+-----------+\n|         IOT|      15000|\n|    Big Data|      13000|\n|Data Science|      43000|\n+------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Finding out which department gives what total salary\n",
    "df.groupBy('Department').sum('Salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2c86714-372c-449d-92af-75647ac5068e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n|  Department|count|\n+------------+-----+\n|         IOT|    2|\n|    Big Data|    3|\n|Data Science|    4|\n+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Number of People working in a department\n",
    "df.groupBy('Department').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba5371e5-997c-45c4-bfe2-d94cd1d29afe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n|sum(Salary)|\n+-----------+\n|      71000|\n+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Using Aggregate Functions without using group by\n",
    "df.agg({'Salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "685fe6ff-d337-4434-b075-5cf6f4e4222f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[26]: 'Sudhanshu'"
     ]
    }
   ],
   "source": [
    "# Finding out the guy getting maximum Salary\n",
    "df.groupBy('Name').max('Salary').take(1)[0][0]"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "PySpark Tutorial 5",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
